# -*- coding: utf-8 -*-
"""ML_hw_q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mFPpa4aHWhCjzG19OaRaxFwOZj5Yzb7J
"""

import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from numpy import array
from numpy import diag
from numpy import dot
from numpy import zeros
from sklearn.decomposition import PCA
from numpy import dot
from numpy.linalg import inv
from sklearn.metrics import mean_squared_error

"""Generating data"""

X = np.array([3,2,1,2,4,5,1,2,3,0,2,5])
X = np.reshape(X,(4,3))
print(X)

"""Finding sample mean"""

mean = np.mean(X,axis = 0, dtype='float64')
print(f"Mean of the columns of X {mean}")

"""Zero centering of the samples"""

X = X - mean
print(X)

"""<h3>PCA by Eigen value decomposition of covariance matrix</h3>"""

from numpy import cov
from numpy.linalg import eig
V = cov(X.T)
Evalues, Evectors = eig(V)
print(f"Eigen vectors = \n {Evectors}")
print(f"Eigen values = \n {Evalues}")

# Converting Evalues to a diagonal matrix
Evalues_diag = zeros((X.shape[0], X.shape[1]))
Evalues_diag[:X.shape[1], :X.shape[1]] = diag(Evalues)
print(f"Diagonalized form of Evalues = \n {Evalues_diag}")

"""Projecting X using the Eigen vectors"""

k = 2
Evectors_k = Evectors[:,0:k]
proj = X.dot(Evectors_k)
print(f"Selecting 2 principal axes = \n {Evectors_k}")
print("\n")
print(f"Projected X using the above principal axes = \n {proj}")

"""Reconstruction of X"""

recon = proj.dot(Evectors_k.T)+mean
print(f"Reconstruction of X using the new basis = \n {recon}")

"""Reconstruction error"""

print(mean_squared_error(X+mean, recon))

"""<h3>An alternate way to perform PCA: PCA by singular value decomposition of data matrix</h3>"""

U, S, VT = np.linalg.svd(X)

print(f"Unitary matrix = \n {U}")
print(f"Shape of unitary matrix = {U.shape}")
print("\n")
print(f"Diagonal matrix of singular values = \n {S}")
print(f"Shape of this matrix = {S.shape}")
print("\n")
print(f"Matrix of principal axes = \n {VT}")
print(f"Shape of this matrix = {VT.shape}")
print("\n")

# Converting S to a diagonal matrix
S_diag = zeros((X.shape[0], X.shape[1]))
S_diag[:X.shape[1], :X.shape[1]] = diag(S)
print(f"Diagonalized form of S = \n {S_diag}")

"""* Eigen vectors are the columns of 'V' or rows of 'VT'.
* Eigen values are present in the diagonal matrix of S.

Reconstruction with minimum loss using first 2 components (k=2)
"""

k = 2
U_k = U.T[0:k][0:k]
U_kT = U_k.T
S_diag_k = S_diag[0:2,0:2]
VT_k = VT[0:k]

"""PC scores or Projected X"""

projectedX = U_kT.dot(S_diag_k)
print(projectedX)

reconstruct_k = U_kT.dot(S_diag_k.dot(VT_k))
reconstruct_k = reconstruct_k + mean
print(reconstruct_k)

"""Reconstruction error"""

print(mean_squared_error(X+mean, reconstruct_k))